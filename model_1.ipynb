{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "module_path = os.path.abspath(os.path.join( 'src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from nb_modules import model as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df = pd.read_pickle('data/pickles/building_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 762106 entries, 0 to 762105\n",
      "Data columns (total 55 columns):\n",
      "building_id                               762106 non-null int64\n",
      "district_id                               762106 non-null int64\n",
      "vdcmun_id                                 762106 non-null int64\n",
      "ward_id                                   762106 non-null int64\n",
      "count_floors_pre_eq                       762106 non-null int64\n",
      "age_building                              762106 non-null int64\n",
      "plinth_area_sq_ft                         762106 non-null int64\n",
      "height_ft_pre_eq                          762106 non-null int64\n",
      "land_surface_condition                    762106 non-null object\n",
      "foundation_type                           762106 non-null object\n",
      "roof_type                                 762106 non-null object\n",
      "ground_floor_type                         762106 non-null object\n",
      "other_floor_type                          762106 non-null object\n",
      "position                                  762106 non-null object\n",
      "plan_configuration                        762106 non-null object\n",
      "has_superstructure_adobe_mud              762106 non-null int64\n",
      "has_superstructure_mud_mortar_stone       762106 non-null int64\n",
      "has_superstructure_stone_flag             762106 non-null int64\n",
      "has_superstructure_cement_mortar_stone    762106 non-null int64\n",
      "has_superstructure_mud_mortar_brick       762106 non-null int64\n",
      "has_superstructure_cement_mortar_brick    762106 non-null int64\n",
      "has_superstructure_timber                 762106 non-null int64\n",
      "has_superstructure_bamboo                 762106 non-null int64\n",
      "has_superstructure_rc_non_engineered      762106 non-null int64\n",
      "has_superstructure_rc_engineered          762106 non-null int64\n",
      "has_superstructure_other                  762106 non-null int64\n",
      "land_surface_condition_num                762106 non-null int64\n",
      "foundation_type_num                       762106 non-null int64\n",
      "roof_type_num                             762106 non-null int64\n",
      "ground_floor_type_num                     762106 non-null int64\n",
      "other_floor_type_num                      762106 non-null int64\n",
      "position_num                              762106 non-null int64\n",
      "plan_configuration_num                    762106 non-null int64\n",
      "target                                    762106 non-null int64\n",
      "has_geotechnical_risk                     762106 non-null int64\n",
      "has_geotechnical_risk_land_settlement     762106 non-null int64\n",
      "has_geotechnical_risk_fault_crack         762106 non-null int64\n",
      "has_geotechnical_risk_liquefaction        762106 non-null int64\n",
      "has_geotechnical_risk_landslide           762106 non-null int64\n",
      "has_geotechnical_risk_rock_fall           762106 non-null int64\n",
      "has_geotechnical_risk_flood               762106 non-null int64\n",
      "has_geotechnical_risk_other               762106 non-null int64\n",
      "legal_ownership_status                    762106 non-null object\n",
      "has_secondary_use                         762106 non-null float64\n",
      "has_secondary_use_agriculture             762106 non-null int64\n",
      "has_secondary_use_hotel                   762106 non-null int64\n",
      "has_secondary_use_rental                  762106 non-null int64\n",
      "has_secondary_use_institution             762106 non-null int64\n",
      "has_secondary_use_school                  762106 non-null int64\n",
      "has_secondary_use_industry                762106 non-null int64\n",
      "has_secondary_use_health_post             762106 non-null int64\n",
      "has_secondary_use_gov_office              762106 non-null int64\n",
      "has_secondary_use_use_police              762106 non-null int64\n",
      "has_secondary_use_other                   762106 non-null int64\n",
      "legal_ownership_status_num                762106 non-null int64\n",
      "dtypes: float64(1), int64(46), object(8)\n",
      "memory usage: 325.6+ MB\n"
     ]
    }
   ],
   "source": [
    "building_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'district_id', 'vdcmun_id', 'ward_id',\n",
       "       'count_floors_pre_eq', 'age_building', 'plinth_area_sq_ft',\n",
       "       'height_ft_pre_eq', 'land_surface_condition', 'foundation_type',\n",
       "       'roof_type', 'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'land_surface_condition_num', 'foundation_type_num', 'roof_type_num',\n",
       "       'ground_floor_type_num', 'other_floor_type_num', 'position_num',\n",
       "       'plan_configuration_num', 'target', 'has_geotechnical_risk',\n",
       "       'has_geotechnical_risk_land_settlement',\n",
       "       'has_geotechnical_risk_fault_crack',\n",
       "       'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_landslide',\n",
       "       'has_geotechnical_risk_rock_fall', 'has_geotechnical_risk_flood',\n",
       "       'has_geotechnical_risk_other', 'legal_ownership_status',\n",
       "       'has_secondary_use', 'has_secondary_use_agriculture',\n",
       "       'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
       "       'has_secondary_use_institution', 'has_secondary_use_school',\n",
       "       'has_secondary_use_industry', 'has_secondary_use_health_post',\n",
       "       'has_secondary_use_gov_office', 'has_secondary_use_use_police',\n",
       "       'has_secondary_use_other', 'legal_ownership_status_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    60.31\n",
      "1    21.79\n",
      "2    17.90\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(round(building_df['target'].value_counts(normalize=True)*100,2))\n",
    "sns.catplot(x=\"target\", kind=\"count\", palette=\"ch:.25\", data=building_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some level of class imbalance. 60% of the buildings in the dataset have severe or Grade 3 damage, while about 22% are buildings of Grade 1 with minor damages and 18% of buildings are of Grade 2 or major damages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split for base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features:  (609684, 46) Target:  (609684,)\n",
      "Test set - Features:  (152422, 46) Target:  (152422,)\n",
      "============================================ \n",
      "3    0.603185\n",
      "1    0.217613\n",
      "2    0.179203\n",
      "Name: target, dtype: float64\n",
      "3    0.602656\n",
      "1    0.219188\n",
      "2    0.178157\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_droplist = ['target','legal_ownership_status', 'land_surface_condition', 'foundation_type',\n",
    "       'roof_type', 'ground_floor_type', 'other_floor_type', 'plan_configuration', 'position']\n",
    "\n",
    "X = building_df.drop(columns=X_droplist)\n",
    "y = building_df['target']\n",
    "\n",
    "#performing train-test split on main dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, test_size=0.2)\n",
    "\n",
    "#checking the shape of the training set and test set\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape,)\n",
    "print(\"Test set - Features: \", X_test.shape, \"Target: \",y_test.shape,)\n",
    "print('============================================ ')\n",
    "print(y_train.value_counts(normalize = True))\n",
    "print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL\n",
    "Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.6027\n",
      "Train Accuracy score:  0.6032\n",
      "================================\n",
      "Test F1 score:  0.4532\n",
      "Train F1 score:  0.4539\n",
      "================================\n",
      "Test Recall score:  0.6027\n",
      "Train Recall score:  0.6032\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(solver='lbfgs',multi_class='multinomial', random_state=100)\n",
    "\n",
    "lr1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = lr1.predict(X_test)\n",
    "y_pred_train = lr1.predict(X_train)\n",
    "\n",
    "# checking accuracy score\n",
    "print('Test Accuracy score: ', round(metrics.accuracy_score(y_test, y_pred_test),4))\n",
    "print('Train Accuracy score: ', round(metrics.accuracy_score(y_train, y_pred_train),4))\n",
    "print('================================')\n",
    "# checking f1 score\n",
    "print('Test F1 score: ', round(metrics.f1_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train F1 score: ', round(metrics.f1_score(y_train, y_pred_train, average='weighted'),4))\n",
    "print('================================')\n",
    "# checking recall score\n",
    "print('Test Recall score: ', round(metrics.recall_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train Recall score: ', round(metrics.recall_score(y_train, y_pred_train, average='weighted'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_eval= {}\n",
    "mod_eval['baseline_lr1']={'accuracy': .6027, 'f1':0.4532, 'recall': 0.6032}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of nominal variables that may best be turned to dummies. The corresponding *'num'* features will be added to the drop list to be removed from the main dataset to be used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_list=['dummy_1','dummy_2','dummy_3','dummy_4','dummy_5','dummy_6','dummy_7','dummy_8','dummy_9']\n",
    "# nom_feats= ['ward_id', 'land_surface_condition', 'foundation_type',\n",
    "#        'roof_type', 'ground_floor_type', 'other_floor_type', 'position',\n",
    "#        'plan_configuration','legal_ownership_status' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dummy, feat in zip(dummy_list, nom_feats):\n",
    "#     print(dummy, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dummy, feat in zip(dummy_list, nom_feats):\n",
    "#     dummy = pd.DataFrame()\n",
    "#     dummy = mod.dummify(building_df, feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_1 = mod.dummify(building_df, 'ward_id')\n",
    "dummy_2 = mod.dummify(building_df, 'land_surface_condition')\n",
    "dummy_3 = mod.dummify(building_df, 'foundation_type')\n",
    "dummy_4 = mod.dummify(building_df, 'roof_type')\n",
    "dummy_5 = mod.dummify(building_df, 'ground_floor_type')\n",
    "dummy_6 = mod.dummify(building_df, 'other_floor_type')\n",
    "dummy_7 = mod.dummify(building_df, 'position')\n",
    "dummy_8 = mod.dummify(building_df, 'plan_configuration')\n",
    "dummy_9 = mod.dummify(building_df, 'legal_ownership_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we drop all the dummified features, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list= ['ward_id', 'land_surface_condition', 'foundation_type',\n",
    "       'roof_type', 'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration','legal_ownership_status', 'land_surface_condition_num', \n",
    "            'foundation_type_num', 'roof_type_num',\n",
    "       'ground_floor_type_num', 'other_floor_type_num', 'position_num', \n",
    "            'plan_configuration_num', 'legal_ownership_status_num', \n",
    "            'has_secondary_use', 'has_geotechnical_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df.drop(columns= drop_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762106, 36)\n",
      "(762106, 18)\n",
      "(762106, 2)\n",
      "(762106, 4)\n",
      "(762106, 2)\n",
      "(762106, 4)\n",
      "(762106, 3)\n",
      "(762106, 3)\n",
      "(762106, 9)\n",
      "(762106, 3)\n"
     ]
    }
   ],
   "source": [
    "df_list= [building_df, dummy_1 , dummy_2 , dummy_3 , dummy_4 , dummy_5 , dummy_6 , dummy_7 , dummy_8 , dummy_9]\n",
    "for df in df_list:\n",
    "    print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['target']\n",
    "X.drop(['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762106, 83)\n",
      "(762106,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Instantiating polynomial features object\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# # applying polynomial feature object to data\n",
    "# poly_data = poly.fit_transform(X)\n",
    "\n",
    "# #assigning feature names from main dataframe\n",
    "# poly_columns = poly.get_feature_names(X.columns)\n",
    "\n",
    "# #converting array to dataframe\n",
    "# df_poly = pd.DataFrame(poly_data, columns = poly_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762106, 3569)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872.9868269338318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sqrt(762106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split - dataset after polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #performing train-test split on main dataframe\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_poly, y, random_state=100, test_size=0.3)\n",
    "\n",
    "# #checking the shape of the training set and test set\n",
    "# print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape,)\n",
    "# print(\"Test set - Features: \", X_test.shape, \"Target: \",y_test.shape,)\n",
    "# print('============================================ ')\n",
    "# print(y_train.value_counts(normalize = True))\n",
    "# print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA Step-by-step**\n",
    "* It is important to center and standardize your data. PCA lives off of correlation and covariance of your data, and using wildly different scales could lead to inflated weights for the linear combination. Let's call this centered and standardized matrix Z.\n",
    "* Calculate a covariance matrix of p x p where p responds to number of predictors.\n",
    "* Calculate the eigenvectors and eigenvalues of the covariance matrix.\n",
    "* Arrange the eigenvalues from largest to smallest. You should obtain p eigenvalues which correspond to number of components.\n",
    "* Choose the amount of components you want to include based on number of variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess the data \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# x = df_poly.loc.values\n",
    "# # Separating out the target\n",
    "# #y = df.loc[:,['mpg']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features:  (457263, 83) Target:  (457263,)\n",
      "Test set - Features:  (304843, 83) Target:  (304843,)\n",
      "============================================ \n",
      "3    0.603718\n",
      "1    0.217566\n",
      "2    0.178716\n",
      "Name: target, dtype: float64\n",
      "3    0.60212\n",
      "1    0.21847\n",
      "2    0.17941\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#performing train-test split on main dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, test_size=0.4)\n",
    "\n",
    "#checking the shape of the training set and test set\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape,)\n",
    "print(\"Test set - Features: \", X_test.shape, \"Target: \",y_test.shape,)\n",
    "print('============================================ ')\n",
    "print(y_train.value_counts(normalize = True))\n",
    "print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "Going forward to tackle the class imbalance problem in the data, we will use a class weight dictionary to defince the class weight to be used in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    60.31\n",
       "1    21.79\n",
       "2    17.90\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(y.value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw= {3: 20, 1: 35, 2: 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unweighted Multiclass Logistic Regression Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.6021\n",
      "Train Accuracy score:  0.6037\n",
      "================================\n",
      "Test F1 score:  0.4526\n",
      "Train F1 score:  0.4545\n",
      "================================\n",
      "Test Recall score:  0.6021\n",
      "Train Recall score:  0.6037\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(solver='lbfgs',multi_class='multinomial', \n",
    "                                random_state=100, max_iter=1000, C=1e4,\n",
    "                                verbose=1, n_jobs=-1)\n",
    "\n",
    "lr2.fit(X_train, y_train) #fit logreg model on n_features = 50\n",
    "\n",
    "# class predictions (not predicted probabilities)\n",
    "y_pred_test = lr2.predict(X_test)\n",
    "y_pred_train = lr2.predict(X_train)\n",
    "\n",
    "# checking accuracy score\n",
    "print('Test Accuracy score: ', round(metrics.accuracy_score(y_test, y_pred_test),4))\n",
    "print('Train Accuracy score: ', round(metrics.accuracy_score(y_train, y_pred_train),4))\n",
    "print('================================')\n",
    "# checking f1 score\n",
    "print('Test F1 score: ', round(metrics.f1_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train F1 score: ', round(metrics.f1_score(y_train, y_pred_train, average='weighted'),4))\n",
    "print('================================')\n",
    "# checking recall score\n",
    "print('Test Recall score: ', round(metrics.recall_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train Recall score: ', round(metrics.recall_score(y_train, y_pred_train, average='weighted'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Multiclass Logistic Regression Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.6021\n",
      "Train Accuracy score:  0.6037\n",
      "================================\n",
      "Test F1 score:  0.4526\n",
      "Train F1 score:  0.4545\n",
      "================================\n",
      "Test Recall score:  0.6021\n",
      "Train Recall score:  0.6037\n"
     ]
    }
   ],
   "source": [
    "lr3 = LogisticRegression(class_weight=cw, solver='lbfgs',multi_class='multinomial', \n",
    "                                random_state=100, max_iter=1000, C=1e4,\n",
    "                                verbose=1, n_jobs=-1 )\n",
    "\n",
    "lr3.fit(X_train, y_train) \n",
    "\n",
    "# class predictions (not predicted probabilities)\n",
    "y_pred_test = lr3.predict(X_test)\n",
    "y_pred_train = lr3.predict(X_train)\n",
    "\n",
    "# checking accuracy score\n",
    "print('Test Accuracy score: ', round(metrics.accuracy_score(y_test, y_pred_test),4))\n",
    "print('Train Accuracy score: ', round(metrics.accuracy_score(y_train, y_pred_train),4))\n",
    "print('================================')\n",
    "# checking f1 score\n",
    "print('Test F1 score: ', round(metrics.f1_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train F1 score: ', round(metrics.f1_score(y_train, y_pred_train, average='weighted'),4))\n",
    "print('================================')\n",
    "# checking recall score\n",
    "print('Test Recall score: ', round(metrics.recall_score(y_test, y_pred_test, average='weighted'),4))\n",
    "print('Train Recall score: ', round(metrics.recall_score(y_train, y_pred_train, average='weighted'),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN ---- scaling with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scale1 = scaler.transform(X_train)  \n",
    "X_test_scale1 = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-40dac231ae0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scale1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lhams/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lhams/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    456\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    457\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs = -1)\n",
    "\n",
    "knn.fit(X_train_scale1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scale1 =knn.predict(X_test_scale1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-02a51745a1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scale1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_scale1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scale1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lhams/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lhams/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    456\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    457\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('f1score - all scaled:' + str(round(metrics.f1_score(y_test, y_pred_scale1, average='weighted'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
